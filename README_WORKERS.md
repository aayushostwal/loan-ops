# Multiple Hatchet Workers - Quick Reference

## ğŸš€ Quick Start

### Start 2 Workers (Default)
```bash
./start_workers.sh
```

### Start Custom Number of Workers
```bash
./start_workers.sh 4    # Start 4 workers
./start_workers.sh 8    # Start 8 workers
```

### Start Single Worker (Development)
```bash
./start_worker.sh
```

## ğŸ“Š What You Get

âœ… **Parallel Processing**: Multiple workflows processed simultaneously  
âœ… **Higher Throughput**: Handle more uploads concurrently  
âœ… **Fault Tolerance**: If one worker crashes, others continue  
âœ… **Easy Scaling**: Add more workers as demand grows  

## ğŸ“ Monitor Workers

```bash
# Watch all worker logs
tail -f logs/worker_*.log

# Watch specific worker
tail -f logs/worker_1.log

# Check running workers
ps aux | grep worker.py
```

## ğŸ›‘ Stop Workers

Press `Ctrl+C` in the terminal where workers are running.

## ğŸ“– Full Documentation

See **WORKERS_GUIDE.md** for:
- Architecture details
- Performance tuning
- Production deployment
- Troubleshooting
- Best practices

## ğŸ’¡ When to Use Multiple Workers

| Scenario | Recommended Workers |
|----------|-------------------|
| Local Development | 1 |
| Testing | 1-2 |
| Production (Low Load) | 2-4 |
| Production (High Load) | 4-8 |
| Production (Very High Load) | 8-16 |

## ğŸ”§ What Workers Do

1. **Lender Processing**: Extract and process data from uploaded lender documents
2. **Loan Matching**: Match loan applications against all lenders in parallel

## âš™ï¸ Configuration

Workers read from `.env`:
- `HATCHET_CLIENT_TOKEN` - Required (get from https://cloud.onhatchet.run/)
- `OPENAI_API_KEY` - Required for LLM processing
- `DATABASE_URL` - Database connection

## ğŸ¯ Architecture

```
API Upload â†’ Hatchet Cloud â†’ Worker Pool â†’ Database
                â†“
         [Worker 1, Worker 2, Worker 3, ...]
```

Each worker independently pulls and processes workflows from Hatchet.

